#!/bin/bash

env

source /root/spark_files/configure_spark.sh

IP=$(ip -o -4 addr list eth0 | perl -n -e 'if (m{inet\s([\d\.]+)\/\d+\s}xms) { print $1 }')
echo "MASTER_IP=$IP"

echo "preparing Spark"
prepare_spark $(hostname)

echo "starting etcd-service for name resolution"
cd /root/spark_files/etcd-service
python /root/spark_files/etcd-service/main.py --etcd_directory /etcd_spark/$(hostname)/name_service --etcd_port $ETCD_PORT $ETCD_ADDRESS $HOST_ADDRESS &
cd $SPARK_HOME

echo "starting Hadoop Namenode"
sudo -u hdfs hadoop namenode -format > /dev/null 2>&1
service hadoop-namenode start > /dev/null 2>&1

echo "starting sshd"
/usr/sbin/sshd

sleep 5

echo "starting Spark Master"
cp /root/spark_master_files/run_spark_master.sh /
chmod a+rx /run_spark_master.sh
sudo -u hdfs SPARK_VERSION=$SPARK_VERSION /run_spark_master.sh
