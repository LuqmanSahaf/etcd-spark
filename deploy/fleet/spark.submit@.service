[Unit]
Description=Spark Submit

[Service]
TimeoutStartSec=0
ExecStartPre=-/usr/bin/docker kill spark_submit%i
ExecStartPre=-/usr/bin/docker rm spark_submit%i
ExecStartPre=/usr/bin/docker pull luckysahaf/spark-submit:1.1.0
EnvironmentFile=/etc/environment
ExecStart=/usr/bin/bash -c '\
sudo chmod +x /etc/environment ;\
. /etc/environment ;\
IFS="_" ;\
instance=%i ;\
declare -A toks ;\
count=0 ;\
for n in $instance ; do \
    toks[${count}]=$n ;\
done ;\
master=spark_master${toks[0]} ;\
driver=spark_driver%i ;\
IFS=' ' ;\
driver_dir=/home/core/run/$driver ;\
rm -r $driver_dir ;\
mkdir -p $driver_dir ;\
etcdctl get /etcd_spark/$master/$driver/spark_defaults > $driver_dir/spark-defaults.conf ;\
to_publish=$(etcdctl get /etcd_spark/$master/$driver/to_publish) ;\
etcdctl get /etcd_spark/$master/$driver/spark_env > $driver_dir/spark-env.sh ;\
echo "export SPARK_LOCAL_IP=${COREOS_PRIVATE_IPV4}" >> $driver_dir/spark-env.sh ;\
etcdctl get /etcd_spark/$master/log4j > $driver_dir/log4j.properties ;\
to_copy=$(etcdctl get /etcd_spark/$master/spark_driver%i/to_copy) ;\
for file_name in to_copy; do ;\
    etcdctl get /etcd_spark/$master/$driver/file_name > $driver_dir/file_name ;\
done ;\
count=0 ;\
publish_args="" ;\
for i in ${to_publish[@]} ;\
do \
    if [ $count == 0 ] ; then \
        count=$(( $count+1 )) ;\
        publish_args="-p $i:$i" ;\
    else \
        publish_args="$publish_args -p ${COREOS_PRIVATE_IPV4}:$i:$i" ;\
    fi ;\
done ;\
env_args="-e ETCD_ADDRESS=${COREOS_PRIVATE_IPV4} -e ETCD_PORT=4001 -e HOST_ADDRESS=${COREOS_PRIVATE_IPV4}" ;\
SPARK_SUBMIT_OPTS=$(etcdctl get /etcd_spark/$master/$driver/spark_submit_opts) ;\
docker run --name $driver -h $driver $publish_args $env_args -v $driver_dir:/home/run luckysahaf/spark-submit:1.1.0 $master $SPARK_SUBMIT_OPTS'
ExecStop=/usr/bin/docker stop spark_driver%i

[X-Fleet]
Conflicts=spark.worker@*.service
