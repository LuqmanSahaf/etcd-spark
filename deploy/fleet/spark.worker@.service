[Unit]
Description=Spark Worker
#After=spark.master@.service

[Service]
TimeoutStartSec=0
ExecStartPre=-/usr/bin/docker kill spark_worker%i
ExecStartPre=-/usr/bin/docker rm spark_worker%i
ExecStartPre=/usr/bin/docker pull luckysahaf/spark-worker:1.1.0
EnvironmentFile=/etc/environment
ExecStart=/usr/bin/bash -c '\
sudo chmod +x /etc/environment ;\
. /etc/environment ;\
IFS="_" ;\
instance=%i ;\
declare -A toks ;\
count=0 ;\
for n in $instance ; do \
    toks[${count}]=$n ;\
done ;\
master=spark_master${toks[0]} ;\
IFS=" " ;\
worker_dir=/home/core/run/spark_worker%i ;\
rm -r $worker_dir ;\
mkdir -p $worker_dir ;\
to_publish=$(etcdctl get /etcd_spark/$master/$worker/to_publish) ;\
datanode_port=$(etcdctl get /etcd_spark/$master/$worker/DATANODE_PORT) ;\
etcdctl get /etcd_spark/$master/$worker/spark_env > $worker_dir/spark-env.sh ;\
worker_ui=$(etcdctl get /etcd_spark/$master/$worker/WORKER_UI) ;\
worker_port=$(etcdctl get /etcd_spark/$master/$worker/WORKER_PORT) ;\
etcdctl get /etcd_spark/$master/log4j > $worker_dir/log4j.properties ;\
echo "export SPARK_WORKER_PORT=$worker_port" >> $worker_dir/spark-env.sh ;\
count=0 ;\
publish_args="" ;\
for i in ${to_publish[@]} ; do \
    if [ $count == 0 ] ; then \
        count=$(( $count+1 )) ;\
        publish_args="-p $i:$i" ;\
    else \
        publish_args="$publish_args -p ${COREOS_PRIVATE_IPV4}:$i:$i" ;\
    fi ;\
done ;\
env_args="-e ETCD_ADDRESS=${COREOS_PRIVATE_IPV4} -e ETCD_PORT=4001 -e HOST_ADDRESS=${COREOS_PRIVATE_IPV4} -e SPARK_WORKER_UI_PORT=$worker_ui -e DATANODE_PORT=$datanode_port" ;\
docker run --name $worker -h $worker $publish_args $env_args -v $worker_dir:/home/run luckysahafspark-worker:1.1.0 $master'
ExecStop=/usr/bin/docker stop spark_worker%i

[X-Fleet]
Conflicts=spark.master@*.service
